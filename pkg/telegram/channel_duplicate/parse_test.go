package channel_duplicate

import "testing"

// TestParseTextURLSimple –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Å—ã–ª–∫–∏ –±–µ–∑ –æ–∫—Ä—É–∂–µ–Ω–∏—è.
func TestParseTextURLSimple(t *testing.T) {
	base := "üòÄ–ü—Ä–∏–≤–µ—Ç" // emoji –∑–∞–Ω–∏–º–∞–µ—Ç –¥–≤–µ –ø–æ–∑–∏—Ü–∏–∏ UTF-16
	add := "[–ú–∏—Ä](https://example.com)"
	ent, clean := parseTextURL(add, utf16Len(base))
	if ent == nil {
		t.Fatalf("—Å—É—â–Ω–æ—Å—Ç—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
	}
	if ent.Offset != utf16Len(base) {
		t.Errorf("–æ–∂–∏–¥–∞–ª—Å—è offset %d, –ø–æ–ª—É—á–µ–Ω %d", utf16Len(base), ent.Offset)
	}
	if ent.Length != utf16Len("–ú–∏—Ä") {
		t.Errorf("–æ–∂–∏–¥–∞–ª–∞—Å—å –¥–ª–∏–Ω–∞ %d, –ø–æ–ª—É—á–µ–Ω–∞ %d", utf16Len("–ú–∏—Ä"), ent.Length)
	}
	if clean != "–ú–∏—Ä" {
		t.Errorf("–æ–∂–∏–¥–∞–ª—Å—è —Ç–µ–∫—Å—Ç '–ú–∏—Ä', –ø–æ–ª—É—á–µ–Ω–æ %q", clean)
	}
}

// TestParseTextURLContext –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É —Å—Å—ã–ª–∫–∏ –≤–Ω—É—Ç—Ä–∏ –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞.
func TestParseTextURLContext(t *testing.T) {
	base := "üòÄ–ü—Ä–∏–≤–µ—Ç" // emoji –∑–∞–Ω–∏–º–∞–µ—Ç –¥–≤–µ –ø–æ–∑–∏—Ü–∏–∏ UTF-16
	add := " –ø–µ—Ä–µ—Ö–æ–¥–∏ –≤ [–≥—Ä—É–ø–ø—É](https://example.com)!"
	ent, clean := parseTextURL(add, utf16Len(base))
	if ent == nil {
		t.Fatalf("—Å—É—â–Ω–æ—Å—Ç—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
	}
	prefixLen := utf16Len(" –ø–µ—Ä–µ—Ö–æ–¥–∏ –≤ ")
	if ent.Offset != utf16Len(base)+prefixLen {
		t.Errorf("–æ–∂–∏–¥–∞–ª—Å—è offset %d, –ø–æ–ª—É—á–µ–Ω %d", utf16Len(base)+prefixLen, ent.Offset)
	}
	if ent.Length != utf16Len("–≥—Ä—É–ø–ø—É") {
		t.Errorf("–æ–∂–∏–¥–∞–ª–∞—Å—å –¥–ª–∏–Ω–∞ %d, –ø–æ–ª—É—á–µ–Ω–∞ %d", utf16Len("–≥—Ä—É–ø–ø—É"), ent.Length)
	}
	if clean != " –ø–µ—Ä–µ—Ö–æ–¥–∏ –≤ –≥—Ä—É–ø–ø—É!" {
		t.Errorf("–æ–∂–∏–¥–∞–ª—Å—è —Ç–µ–∫—Å—Ç ' –ø–µ—Ä–µ—Ö–æ–¥–∏ –≤ –≥—Ä—É–ø–ø—É!', –ø–æ–ª—É—á–µ–Ω–æ %q", clean)
	}
}
